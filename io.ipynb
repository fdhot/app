{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqvIBnd1HiIh",
        "outputId": "8c9418dc-bacc-41a0-c83a-824ced7281cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Edges from Causal Graph:\n",
            "  Node extra_feature1 -> Node anxiety_post: Strength 1.000\n",
            "Error generating parallel coordinates plot: Column not found: \"['group'] not in index\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-c672c7cda200>:561: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
            "  plt.tight_layout()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplified DDQN agent initialized and placeholder training completed.\n",
            "Insights report generated:\n",
            "\n",
            "    Combined Insights Report: Anxiety Intervention Analysis\n",
            "\n",
            "    Grok-base Analysis:\n",
            "    Grok-base Analysis: Summary statistics provide a robust view of participants' average anxiety.\n",
            "\n",
            "Grok-base Analysis: The causal graph suggests potential influences between pre-anxiety, post-anxiety, and group. Further investigation is needed to confirm these relationships.\n",
            "\n",
            "\n",
            "\n",
            "    Claude 3.7 Sonnet Analysis:\n",
            "    Claude 3.7 Sonnet Interpretation: The KDE plot compares distributions of pre-anxiety and post-anxiety, suggesting visible correlations.\n",
            "\n",
            "Claude 3.7 Sonnet Interpretation: The Violin plot details the shapes of anxiety distributions across groups.\n",
            "\n",
            "Claude 3.7 Sonnet Interpretation: The parallel coordinates visualization clearly shows the individual trajectories from pre to post anxiety states, revealing group-specific responses to the intervention.\n",
            "\n",
            "Claude 3.7 Sonnet Interpretation: The hypergraph identifies emerging communities of participants with high pre and post anxiety.\n",
            "\n",
            "Claude 3.7 Sonnet Interpretation: The correlation heatmap provides quantitative evidence for relationships between variables, supporting causal inference through statistical associations.\n",
            "\n",
            "Claude 3.7 Sonnet Interpretation: SHAP values reveal how each variable contributes to post-anxiety, highlighting variability among participants.\n",
            "\n",
            "\n",
            "\n",
            "    Grok-Enhanced Analysis:\n",
            "    Grok-Enhanced Analysis: The correlation heatmap uncovers complex interdependencies in the data that suggest potential root causes and mediating factors in anxiety reduction.\n",
            "\n",
            "Grok-Enhanced Analysis: The parallel coordinates plot reveals detailed individual response patterns to the intervention, with clear group-specific trajectories and notable outliers worthy of further investigation.\n",
            "\n",
            "    Synthesized Summary:\n",
            "    The analyses from our Mixture of Experts framework provides complementary insights into the anxiety intervention dataset. Grok-base highlights statistical robustness and potential causal relationships, noting the strong influence of pre-anxiety. Claude 3.7 Sonnet focuses on visual patterns and feature importance, observing variations between groups and the shift towards lower anxiety levels post-intervention. Grok-Enhanced adds nuanced interpretation of complex relationships, emphasizing the dominance of pre-anxiety with group-specific contextual nuances. The combined insights suggest a multifaceted impact influenced by the intervention, pre-intervention anxiety, and group dynamics, with significant variations and potential for deeper exploration of influential outliers and collaborative networks.\n",
            "\n",
            "    The correlation heatmap combined with regression-based causal inference offers a more robust approach to identifying root causes, revealing that [key finding from the analysis] is likely the primary factor influencing post-intervention anxiety levels. The parallel coordinates visualization further supports this by showing clear patterns in individual trajectories across groups.\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"MoE Framework for Anxiety Explainability - Grok & Claude with DDQN, SHAP (Refactored)\n",
        "\n",
        "Mixture of Experts Framework for Enhanced Explainability of Anxiety States\n",
        "Pre- and Post-Intervention Across Experimental Groups (Refactored)\n",
        "\n",
        "This notebook implements a mixture of experts (MoE) framework to enhance the\n",
        "explainability of anxiety states before and after interventions across\n",
        "different groups. It combines large language models (LLMs) with causal\n",
        "inference and a (simplified) DDQN agent for potential action recommendations.\n",
        "\n",
        "Workflow:\n",
        "1. Data Loading and Validation: Load synthetic anxiety intervention data, validate its structure, content, and data types. Handle potential errors gracefully.\n",
        "2. Data Preprocessing: One-hot encode categorical features and scale numerical features.\n",
        "3. Causal Structure Discovery (Regression-Based):  Use regression to infer potential causal relationships.\n",
        "4. SHAP Value Calculation: Compute SHAP values to assess feature importance.\n",
        "5. Data Visualization: Generate KDE, Violin, Parallel Coordinates, Hypergraph, and Correlation Heatmap plots.\n",
        "6. Statistical Summary: Perform bootstrap analysis and generate summary statistics.\n",
        "7. DDQN Agent (Simplified):  A simplified DDQN agent is included as a *placeholder* for potential action recommendations based on the analysis.  This is NOT a fully trained or integrated RL component.\n",
        "8. LLM Insights Report: Synthesize findings using Grok, Claude, and Grok-Enhanced, emphasizing explainability and the combination of different analysis techniques.\n",
        "\n",
        "Keywords: Mixture of Experts, Anxiety States, Pre-Intervention Anxiety, Post-Intervention Anxiety, Causal Inference, LLMs, Explainability, Group Dynamics, DDQN, SHAP, Data Visualization, Regression-Based Causal Discovery\n",
        "\"\"\"\n",
        "\n",
        "# Suppress warnings (use with caution in production code)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"plotly\")\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import shap\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "from itertools import combinations  # For generating combinations of features\n",
        "import plotly.express as px\n",
        "from scipy.stats import bootstrap\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Google Colab specific - Mounting Google Drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    COLAB_ENV = True\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "    print(\"Not running in Google Colab environment.\")\n",
        "\n",
        "# Constants\n",
        "OUTPUT_PATH = \"./output_anxiety_moe/\" if not COLAB_ENV else \"/content/drive/MyDrive/output_anxiety_moe/\"\n",
        "PARTICIPANT_ID_COLUMN = \"participant_id\"\n",
        "GROUP_COLUMN = \"group\"  # Original group column name\n",
        "ANXIETY_PRE_COLUMN = \"anxiety_pre\"\n",
        "ANXIETY_POST_COLUMN = \"anxiety_post\"\n",
        "MODEL_GROK_NAME = \"grok-base\"\n",
        "MODEL_CLAUDE_NAME = \"claude-3.7-sonnet\"\n",
        "MODEL_GROK_ENHANCED_NAME = \"grok-enhanced\"\n",
        "LINE_WIDTH = 2.5\n",
        "BOOTSTRAP_RESAMPLES = 500\n",
        "\n",
        "# IMPORTANT SECURITY WARNING (Placeholder keys)\n",
        "GROK_API_KEY = \"YOUR_API\"  # Placeholder\n",
        "CLAUDE_API_KEY = \"YOUR_API\" # Placeholder\n",
        "\n",
        "def create_output_directory(path):\n",
        "    \"\"\"Creates the output directory if it doesn't exist, handling errors.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        return True\n",
        "    except OSError as e:\n",
        "        print(f\"Error creating output directory: {e}\")\n",
        "        return False\n",
        "\n",
        "def load_data_from_synthetic_string(csv_string):\n",
        "    \"\"\"Loads data from a CSV string, handling errors.\"\"\"\n",
        "    try:\n",
        "        csv_file = StringIO(csv_string)\n",
        "        return pd.read_csv(csv_file)\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error parsing CSV data: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "def validate_dataframe(df, required_columns):\n",
        "    \"\"\"Validates the DataFrame: checks for missing columns, non-numeric data,\n",
        "    duplicate participant IDs, valid group labels, and plausible anxiety ranges.\n",
        "    Returns True if valid, False otherwise.\n",
        "    \"\"\"\n",
        "    if df is None:\n",
        "        print(\"Error: DataFrame is None. Cannot validate.\")\n",
        "        return False\n",
        "\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        print(f\"Error: Missing columns: {missing_columns}\")\n",
        "        return False\n",
        "\n",
        "    for col in required_columns:\n",
        "        if col != PARTICIPANT_ID_COLUMN and col != GROUP_COLUMN:\n",
        "            if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "                print(f\"Error: Non-numeric values found in column: {col}\")\n",
        "                return False\n",
        "\n",
        "    if df[PARTICIPANT_ID_COLUMN].duplicated().any():\n",
        "        print(\"Error: Duplicate participant IDs found.\")\n",
        "        return False\n",
        "\n",
        "    valid_groups = [\"Group 1\", \"Group 2\"]  # Define valid group names\n",
        "    invalid_groups = df[~df[GROUP_COLUMN].isin(valid_groups)][GROUP_COLUMN].unique()\n",
        "    if invalid_groups.size > 0:\n",
        "        print(f\"Error: Invalid group labels found: {invalid_groups}\")\n",
        "        return False\n",
        "\n",
        "    for col in [ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN]:\n",
        "        if df[col].min() < 0 or df[col].max() > 10: # Assuming anxiety is on 0-10 scale\n",
        "            print(f\"Error: Anxiety scores in column '{col}' are out of range (0-10).\")\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def analyze_text_with_llm(text, model_name):\n",
        "    \"\"\"Simulates text analysis by different language models.\"\"\"\n",
        "    text_lower = text.lower()  # Normalize text to lowercase\n",
        "\n",
        "    if model_name == MODEL_GROK_NAME:\n",
        "        # Simulation for Grok-base\n",
        "        if \"causal graph\" in text_lower:\n",
        "            return \"Grok-base Analysis: The causal graph suggests potential influences between pre-anxiety, post-anxiety, and group. Further investigation is needed to confirm these relationships.\"\n",
        "        elif \"shap summary\" in text_lower:\n",
        "            return \"Grok-base Analysis: SHAP values indicate the relative importance of group and pre-anxiety in predicting post-anxiety. Pre-anxiety is a strong predictor.\"\n",
        "        elif \"kde plot\" in text_lower or \"violin plot\" in text_lower:\n",
        "            return \"Grok-base Analysis: KDE and Violin plots show distributions of pre-anxiety and post-anxiety, suggesting variations between groups.\"\n",
        "        elif \"hypergraph\" in text_lower:\n",
        "            return \"Grok-base Analysis: The hypergraph highlights clusters of influential participants based on pre-anxiety and post-anxiety.\"\n",
        "        elif \"summary statistics\" in text_lower:\n",
        "            return \"Grok-base Analysis: Summary statistics provide a robust view of participants' average anxiety.\"\n",
        "        elif \"parallel coordinates\" in text_lower:\n",
        "            return \"Grok-base Analysis: The parallel coordinates plot effectively shows how anxiety levels change from pre to post intervention across different groups, highlighting group-specific patterns and trends.\"\n",
        "        elif \"heatmap\" in text_lower:\n",
        "            return \"Grok-base Analysis: The correlation heatmap reveals potential causal factors by highlighting the strength of relationships between variables.\"\n",
        "        else:\n",
        "            return (\n",
        "                f\"General Grok-base analysis on: '{text}'. Suggests deeper investigation into metrics.\"\n",
        "            )\n",
        "\n",
        "    elif model_name == MODEL_CLAUDE_NAME:\n",
        "        # Simulation for Claude 3.7 Sonnet\n",
        "        if \"causal graph\" in text_lower:\n",
        "            return \"Claude 3.7 Sonnet Interpretation: The causal graph shows potential dependencies and possible confounding factors between participant anxiety metrics.\"\n",
        "        elif \"shap summary\" in text_lower:\n",
        "            return \"Claude 3.7 Sonnet Interpretation: SHAP values reveal how each variable contributes to post-anxiety, highlighting variability among participants.\"\n",
        "        elif \"kde plot\" in text_lower:\n",
        "            return \"Claude 3.7 Sonnet Interpretation: The KDE plot compares distributions of pre-anxiety and post-anxiety, suggesting visible correlations.\"\n",
        "        elif \"violin plot\" in text_lower:\n",
        "            return \"Claude 3.7 Sonnet Interpretation: The Violin plot details the shapes of anxiety distributions across groups.\"\n",
        "        elif \"hypergraph\" in text_lower:\n",
        "            return \"Claude 3.7 Sonnet Interpretation: The hypergraph identifies emerging communities of participants with high pre and post anxiety.\"\n",
        "        elif \"summary statistics\" in text_lower:\n",
        "            return \"Claude 3.7 Sonnet Interpretation: Statistics provide a quantitative basis for understanding the overall impact of the intervention on anxiety levels.\"\n",
        "        elif \"parallel coordinates\" in text_lower:\n",
        "            return \"Claude 3.7 Sonnet Interpretation: The parallel coordinates visualization clearly shows the individual trajectories from pre to post anxiety states, revealing group-specific responses to the intervention.\"\n",
        "        elif \"heatmap\" in text_lower:\n",
        "            return \"Claude 3.7 Sonnet Interpretation: The correlation heatmap provides quantitative evidence for relationships between variables, supporting causal inference through statistical associations.\"\n",
        "        else:\n",
        "            return (\n",
        "                f\"General Claude 3.7 Sonnet analysis on: '{text}'. Suggests focus on actionable data patterns.\"\n",
        "            )\n",
        "\n",
        "    elif model_name == MODEL_GROK_ENHANCED_NAME:\n",
        "        # Simulation for Grok-Enhanced\n",
        "        if \"causal graph\" in text_lower:\n",
        "            return \"Grok-Enhanced Analysis: The causal graph reveals subtle connections between pre-anxiety and post-anxiety, with group as a key moderator.\"\n",
        "        elif \"shap summary\" in text_lower:\n",
        "            return \"Grok-Enhanced Analysis: SHAP values show that pre-anxiety dominates post-anxiety prediction, but group adds important nuances.\"\n",
        "        elif \"kde plot\" in text_lower:\n",
        "            return \"Grok-Enhanced Analysis: The KDE plot highlights anxiety peaks in certain groups, suggesting significant trends.\"\n",
        "        elif \"violin plot\" in text_lower:\n",
        "            return \"Grok-Enhanced Analysis: The Violin plot displays variations in anxiety distribution, with long tails indicating influential outliers.\"\n",
        "        elif \"hypergraph\" in text_lower:\n",
        "            return \"Grok-Enhanced Analysis: The hypergraph connects participants in influence networks, revealing emerging collaboration patterns.\"\n",
        "        elif \"summary statistics\" in text_lower:\n",
        "            return \"Grok-Enhanced Analysis: Summary statistics point to a stable average anxiety, but with high variability among participants.\"\n",
        "        elif \"parallel coordinates\" in text_lower:\n",
        "            return \"Grok-Enhanced Analysis: The parallel coordinates plot reveals detailed individual response patterns to the intervention, with clear group-specific trajectories and notable outliers worthy of further investigation.\"\n",
        "        elif \"heatmap\" in text_lower:\n",
        "            return \"Grok-Enhanced Analysis: The correlation heatmap uncovers complex interdependencies in the data that suggest potential root causes and mediating factors in anxiety reduction.\"\n",
        "        else:\n",
        "            return (\n",
        "                f\"General Grok-Enhanced analysis on: '{text}'. Recommends exploring interdisciplinary connections in the data.\"\n",
        "            )\n",
        "    else:\n",
        "        return f\"Model '{model_name}' not supported in this simulation.\"\n",
        "\n",
        "class DDQNAgent:\n",
        "    \"\"\"\n",
        "    A simplified DDQN agent for demonstration purposes.  This is a *placeholder*\n",
        "    and would need significant adaptation for a real-world application.\n",
        "    \"\"\"\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        # Initialize Q-network and target network with random values (for demonstration)\n",
        "        self.q_network = np.random.rand(state_dim, action_dim)\n",
        "        self.target_network = np.copy(self.q_network)\n",
        "\n",
        "    def act(self, state, epsilon=0.01):\n",
        "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
        "        if np.random.rand() < epsilon:\n",
        "            return np.random.choice(self.action_dim)  # Explore\n",
        "        else:\n",
        "            return np.argmax(self.q_network[state])  # Exploit\n",
        "\n",
        "    def learn(self, batch, gamma=0.99, learning_rate=0.1):\n",
        "        \"\"\"Placeholder learning function.  A real implementation would update the Q-network.\"\"\"\n",
        "        for state, action, reward, next_state in batch:\n",
        "            # Simplified DDQN update (replace with actual update rule)\n",
        "            q_target = reward + gamma * np.max(self.target_network[next_state])\n",
        "            q_predict = self.q_network[state, action]\n",
        "            self.q_network[state, action] += learning_rate * (q_target - q_predict)\n",
        "\n",
        "    def update_target_network(self):\n",
        "        \"\"\"Placeholder target network update.\"\"\"\n",
        "        self.target_network = np.copy(self.q_network)\n",
        "\n",
        "def scale_data(df, columns):\n",
        "    \"\"\"Scales specified columns using MinMaxScaler, handling errors.\"\"\"\n",
        "    try:\n",
        "        scaler = MinMaxScaler()\n",
        "        df[columns] = scaler.fit_transform(df[columns])\n",
        "        return df\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during data scaling: {e}\")\n",
        "        return None  # Or raise the exception\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during scaling: {e}\")\n",
        "        return None\n",
        "\n",
        "def discover_causal_structure_with_regression(df, variables, output_path):\n",
        "    \"\"\"\n",
        "    Alternative approach to discover causal structure using regression-based methods.\n",
        "    This function doesn't rely on the causal-learn library.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create a graph to represent causal relationships\n",
        "        G = nx.DiGraph()\n",
        "        G.add_nodes_from(variables)\n",
        "\n",
        "        # Dictionary to store relationship strengths\n",
        "        edge_strengths = {}\n",
        "\n",
        "        # Use regression to test possible causal relationships\n",
        "        # Testing if each pair of variables might have a causal relationship\n",
        "        for target in variables:\n",
        "            if target == ANXIETY_POST_COLUMN:  # Focus on predicting post-anxiety\n",
        "                # Potential predictors are all variables except the target\n",
        "                predictors = [var for var in variables if var != target]\n",
        "\n",
        "                # Fit a linear regression model\n",
        "                X = df[predictors]\n",
        "                y = df[target]\n",
        "                model = LinearRegression()\n",
        "                model.fit(X, y)\n",
        "\n",
        "                # Evaluate model performance\n",
        "                y_pred = model.predict(X)\n",
        "                mse = mean_squared_error(y, y_pred)\n",
        "\n",
        "                # Get coefficients\n",
        "                coeffs = dict(zip(predictors, model.coef_))\n",
        "\n",
        "                # Add edges for significant predictors (arbitrary threshold)\n",
        "                for predictor, coef in coeffs.items():\n",
        "                    if abs(coef) > 0.1:  # Arbitrary threshold for significance\n",
        "                        G.add_edge(predictor, target, weight=abs(coef))\n",
        "                        edge_strengths[(predictor, target)] = abs(coef)\n",
        "\n",
        "        # Draw and save the causal graph\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.style.use('dark_background') # Set dark background\n",
        "        pos = nx.spring_layout(G)\n",
        "\n",
        "        # Draw nodes\n",
        "        nx.draw_networkx_nodes(G, pos, node_color=\"#00FFFF\", node_size=700, alpha=0.8)\n",
        "\n",
        "        # Draw edges with varying thickness based on weight\n",
        "        edge_weights = [G[u][v]['weight'] * 2 for u, v in G.edges()]\n",
        "        nx.draw_networkx_edges(G, pos, width=edge_weights, edge_color=\"#FF00FF\", alpha=0.7)\n",
        "\n",
        "        # Draw labels\n",
        "        nx.draw_networkx_labels(G, pos, font_color=\"white\", font_size=12)\n",
        "\n",
        "        # Add edge labels (weights)\n",
        "        edge_labels = {(u, v): f\"{G[u][v]['weight']:.2f}\" for u, v in G.edges()}\n",
        "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color=\"yellow\")\n",
        "\n",
        "        plt.title(\"Regression-Based Causal Graph\", color=\"white\")\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, \"causal_graph.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Generate text description of edges\n",
        "        edges_info = [\n",
        "            f\"  Node {u} -> Node {v}: Strength {G[u][v]['weight']:.3f}\"\n",
        "            for u, v in G.edges()\n",
        "        ]\n",
        "\n",
        "        edge_info_str = \"\\n\".join(edges_info)\n",
        "        print(\"Edges from Causal Graph:\\n\" + edge_info_str)\n",
        "        return edge_info_str\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during regression-based causal structure discovery: {e}\")\n",
        "        return None\n",
        "\n",
        "def calculate_shap_values(df, feature_columns, target_column, output_path):\n",
        "    \"\"\"Calculates and visualizes SHAP values, handling one-hot encoded columns.\"\"\"\n",
        "    try:\n",
        "        # Identify one-hot encoded group columns\n",
        "        encoded_group_cols = [col for col in df.columns if col.startswith(f\"{GROUP_COLUMN}_\")]\n",
        "\n",
        "        # Combine encoded group columns with other feature columns (excluding the original GROUP_COLUMN)\n",
        "        feature_cols_encoded = encoded_group_cols + [\n",
        "            col for col in feature_columns if col != GROUP_COLUMN and col not in encoded_group_cols\n",
        "        ]\n",
        "\n",
        "        # Train a RandomForestRegressor model\n",
        "        model_rf = RandomForestRegressor(random_state=42).fit(df[feature_cols_encoded], df[target_column])\n",
        "\n",
        "        # Create a TreeExplainer and calculate SHAP values\n",
        "        explainer = shap.TreeExplainer(model_rf)\n",
        "        shap_values = explainer.shap_values(df[feature_cols_encoded])\n",
        "\n",
        "        # Create and save the SHAP summary plot\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.style.use('dark_background')\n",
        "        shap.summary_plot(shap_values, df[feature_cols_encoded], show=False, color_bar=True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, \"shap_summary.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        return f\"SHAP summary for features {feature_cols_encoded} predicting {target_column}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during SHAP value calculation: {e}\")\n",
        "        return \"Error: SHAP value calculation failed.\"\n",
        "\n",
        "def create_kde_plot(df, column1, column2, output_path, colors):\n",
        "    \"\"\"Creates a KDE plot, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use('dark_background')\n",
        "        sns.kdeplot(data=df[column1], color=colors[0], label=column1.capitalize(), linewidth=LINE_WIDTH)\n",
        "        sns.kdeplot(data=df[column2], color=colors[1], label=column2.capitalize(), linewidth=LINE_WIDTH)\n",
        "        plt.title('KDE Plot of Anxiety Levels', color='white')\n",
        "        plt.legend(facecolor='black', edgecolor='white', labelcolor='white')\n",
        "        plt.savefig(os.path.join(output_path, 'kde_plot.png'))\n",
        "        plt.close()\n",
        "        return f\"KDE plot visualizing distributions of {column1} and {column2}\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating KDE plot: Column not found: {e}\")\n",
        "        return \"Error: KDE plot generation failed.  Missing column.\"\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error generating KDE plot: {e}\")\n",
        "        return \"Error: KDE plot generation failed.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while creating KDE plot: {e}\")\n",
        "        return \"Error: KDE plot generation failed.\"\n",
        "\n",
        "def create_violin_plot(df, group_column, y_column, output_path, colors):\n",
        "    \"\"\"Creates a violin plot, handling potential errors and one-hot encoded groups.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use('dark_background')\n",
        "\n",
        "        # Handling group column when already one-hot encoded\n",
        "        encoded_group_cols = [col for col in df.columns if col.startswith(f\"{group_column}_\")]\n",
        "\n",
        "        if len(encoded_group_cols) > 0:\n",
        "            # Create a temporary column for group membership\n",
        "            df['temp_group'] = np.nan\n",
        "            for col in encoded_group_cols:\n",
        "                group_name = col.split('_', 1)[1]  # Extract group name from encoded column\n",
        "                df.loc[df[col] == 1, 'temp_group'] = group_name\n",
        "\n",
        "            # Create violin plot\n",
        "            sns.violinplot(data=df, x='temp_group', y=y_column, palette=colors[:len(encoded_group_cols)], linewidth=LINE_WIDTH)\n",
        "            # Remove the temp group after plotting\n",
        "            df.drop('temp_group', axis=1, inplace=True)\n",
        "        else:\n",
        "            # If group column is already categorical\n",
        "            sns.violinplot(data=df, x=group_column, y=y_column, palette=colors, linewidth=LINE_WIDTH)\n",
        "\n",
        "        plt.title('Violin Plot of Anxiety Distribution by Group', color='white')\n",
        "        plt.savefig(os.path.join(output_path, 'violin_plot.png'))\n",
        "        plt.close()\n",
        "        return f\"Violin plot showing {y_column} across groups\"\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating violin plot: Column not found: {e}\")\n",
        "        return \"Error: Violin plot generation failed. Missing column.\"\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error generating violin plot: {e}\")\n",
        "        return \"Error: Violin plot generation failed.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while creating violin plot: {e}\")\n",
        "        return \"Error: Violin plot generation failed.\"\n",
        "\n",
        "def create_parallel_coordinates_plot(df, group_column, anxiety_pre_column, anxiety_post_column, output_path, colors):\n",
        "    \"\"\"Creates a parallel coordinates plot and returns a text description.\"\"\"\n",
        "    try:\n",
        "        # Prepare data: Need original group names, not one-hot encoded.\n",
        "        plot_df = df[[group_column, anxiety_pre_column, anxiety_post_column]].copy()\n",
        "\n",
        "        # Create a color map for groups\n",
        "        unique_groups = plot_df[group_column].unique()\n",
        "        group_color_map = {group: colors[i % len(colors)] for i, group in enumerate(unique_groups)}\n",
        "\n",
        "        # Map group names to colors\n",
        "        plot_df['color'] = plot_df[group_column].map(group_color_map)\n",
        "\n",
        "        # Create the parallel coordinates plot\n",
        "        fig = px.parallel_coordinates(\n",
        "            plot_df,\n",
        "            color='color',  # Use the new 'color' column\n",
        "            dimensions=[anxiety_pre_column, anxiety_post_column],\n",
        "            title=\"Anxiety Levels: Pre- vs Post-Intervention by Group\",\n",
        "            color_continuous_scale=px.colors.sequential.Viridis, # Using Viridis\n",
        "        )\n",
        "\n",
        "        # Customize appearance\n",
        "        fig.update_layout(\n",
        "            plot_bgcolor='black',\n",
        "            paper_bgcolor='black',\n",
        "            font_color='white',\n",
        "            title_font_size=16,\n",
        "        )\n",
        "\n",
        "        # Instead of saving the image, create a text description\n",
        "        description = (\n",
        "            f\"Parallel Coordinates Plot Description:\\n\"\n",
        "            f\"This plot visualizes the change in anxiety levels from pre-intervention ({anxiety_pre_column}) \"\n",
        "            f\"to post-intervention ({anxiety_post_column}) for each participant.\\n\"\n",
        "            f\"Each line represents a participant, and the color of the line indicates their group membership.\\n\"\n",
        "            f\"The x-axis shows the anxiety levels, and the y-axis represents the two time points (pre and post).\\n\"\n",
        "            f\"The plot allows for easy comparison of individual trajectories and group-level trends.\\n\\n\"\n",
        "            f\"Group Color Mapping:\\n\"\n",
        "        )\n",
        "        for group, color in group_color_map.items():\n",
        "            description += f\"- {group}: {color}\\n\"\n",
        "\n",
        "        # Save the description to a text file\n",
        "        with open(os.path.join(output_path, \"parallel_coordinates_description.txt\"), \"w\") as f:\n",
        "            f.write(description)\n",
        "\n",
        "        return description\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating parallel coordinates plot: Column not found: {e}\")\n",
        "        return \"Error: Parallel coordinates plot generation failed. Missing column.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating parallel coordinates plot: {e}\")\n",
        "        return \"Error: Parallel coordinates plot generation failed.\"\n",
        "\n",
        "def create_correlation_heatmap(df, output_path, colors):\n",
        "    \"\"\"Creates a correlation heatmap, handling errors.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.style.use('dark_background')\n",
        "\n",
        "        # Calculate correlation matrix, only including numeric columns\n",
        "        numeric_df = df.select_dtypes(include=[np.number])\n",
        "        corr_matrix = numeric_df.corr()\n",
        "\n",
        "        # Create mask for upper triangle\n",
        "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "\n",
        "        # Custom colormap with neon colors\n",
        "        custom_colors = ['#FF00FF', '#FFFFFF', '#00FFFF']  # Neon purple, white, neon cyan\n",
        "        colormap = LinearSegmentedColormap.from_list('custom', custom_colors, N=256)\n",
        "\n",
        "        # Create heatmap\n",
        "        sns.heatmap(\n",
        "            corr_matrix,\n",
        "            mask=mask,\n",
        "            cmap=colormap,\n",
        "            vmin=-1,\n",
        "            vmax=1,\n",
        "            center=0,\n",
        "            square=True,\n",
        "            linewidths=0.5,\n",
        "            cbar_kws={\"shrink\": 0.8},\n",
        "            annot=True,\n",
        "            fmt=\".2f\",\n",
        "            annot_kws={\"size\": 10}\n",
        "        )\n",
        "\n",
        "        plt.title(\"Correlation Heatmap for Root Cause Analysis\", fontsize=16, color=\"white\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, \"correlation_heatmap.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        return \"Correlation heatmap showing relationships between variables for causal inference.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating correlation heatmap: {e}\")\n",
        "        return \"Error: Correlation heatmap generation failed.\"\n",
        "\n",
        "def visualize_hypergraph(df, anxiety_pre_column, anxiety_post_column, output_path, colors):\n",
        "    \"\"\"Creates a hypergraph, handling errors.\"\"\"\n",
        "    try:\n",
        "        G = nx.Graph()\n",
        "\n",
        "        participant_ids = df[PARTICIPANT_ID_COLUMN].tolist()\n",
        "        G.add_nodes_from(participant_ids, bipartite=0)\n",
        "\n",
        "        feature_sets = {\n",
        "            \"anxiety_pre_high\": df[PARTICIPANT_ID_COLUMN][\n",
        "                df[anxiety_pre_column] > df[anxiety_pre_column].mean()\n",
        "            ].tolist(),\n",
        "            \"anxiety_post_high\": df[PARTICIPANT_ID_COLUMN][\n",
        "                df[anxiety_post_column] > df[anxiety_post_column].mean()\n",
        "            ].tolist(),\n",
        "        }\n",
        "\n",
        "        feature_nodes = list(feature_sets.keys())\n",
        "        G.add_nodes_from(feature_nodes, bipartite=1)\n",
        "\n",
        "        for feature, participants in feature_sets.items():\n",
        "            for participant in participants:\n",
        "                G.add_edge(participant, feature)\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        plt.style.use('dark_background')\n",
        "\n",
        "        pos = nx.bipartite_layout(G, participant_ids)\n",
        "        color_map = [colors[0] if node in participant_ids else colors[1] for node in G]\n",
        "\n",
        "        nx.draw(\n",
        "            G,\n",
        "            pos,\n",
        "            with_labels=True,\n",
        "            node_color=color_map,\n",
        "            font_color=\"white\",\n",
        "            edge_color=\"gray\",\n",
        "            width=LINE_WIDTH,\n",
        "            node_size=700,\n",
        "            font_size=10,\n",
        "            alpha=0.9\n",
        "        )\n",
        "        plt.title(\"Hypergraph Representation of Anxiety Patterns\", fontsize=16, color=\"white\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, \"hypergraph.png\"))\n",
        "        plt.close()\n",
        "        return \"Hypergraph visualizing participant relationships based on anxiety pre and post intervention\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating hypergraph: {e}\")\n",
        "        return \"Error in hypergraph visualization\"\n",
        "\n",
        "def perform_bootstrap(data, statistic, n_resamples=BOOTSTRAP_RESAMPLES):\n",
        "    \"\"\"Performs bootstrap analysis, handling errors.\"\"\"\n",
        "    try:\n",
        "        bootstrap_result = bootstrap((data,), statistic, n_resamples=n_resamples, method=\"percentile\", random_state=42) # Added random_state\n",
        "        return bootstrap_result.confidence_interval\n",
        "    except Exception as e:\n",
        "        print(f\"Error during bootstrap analysis: {e}\")\n",
        "        return (None, None)\n",
        "\n",
        "def save_summary(df, bootstrap_ci, output_path):\n",
        "    \"\"\"Saves summary statistics, handling errors.\"\"\"\n",
        "    try:\n",
        "        summary_text = df.describe().to_string() + f\"\\nBootstrap CI for anxiety_post mean: {bootstrap_ci}\"\n",
        "        with open(os.path.join(output_path, \"summary.txt\"), \"w\") as f:\n",
        "            f.write(summary_text)\n",
        "        return summary_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving summary statistics: {e}\")\n",
        "        return \"Error: Could not save summary statistics.\"\n",
        "\n",
        "def generate_insights_report(\n",
        "    summary_stats_text,\n",
        "    causal_edges_info,\n",
        "    shap_analysis_info,\n",
        "    kde_plot_desc,\n",
        "    violin_plot_desc,\n",
        "    parallel_coords_desc,\n",
        "    hypergraph_desc,\n",
        "    correlation_heatmap_desc,\n",
        "    output_path,\n",
        "):\n",
        "    \"\"\"Generates an insights report using analyses from Grok, Claude, and Grok-Enhanced, handling errors.\"\"\"\n",
        "    try:\n",
        "        grok_insights = (\n",
        "            analyze_text_with_llm(\n",
        "                f\"Analyze summary statistics:\\n{summary_stats_text}\", MODEL_GROK_NAME\n",
        "            )\n",
        "            + \"\\n\\n\"\n",
        "            + (\n",
        "                analyze_text_with_llm(\n",
        "                    f\"Interpret causal graph edges:\\n{causal_edges_info}\", MODEL_GROK_NAME\n",
        "                )\n",
        "                + \"\\n\\n\"\n",
        "                if causal_edges_info\n",
        "                else \"\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        claude_insights = (\n",
        "            analyze_text_with_llm(f\"Interpret KDE plot: {kde_plot_desc}\", MODEL_CLAUDE_NAME)\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(f\"Interpret Violin plot: {violin_plot_desc}\", MODEL_CLAUDE_NAME)\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(f\"Interpret Parallel Coordinates: {parallel_coords_desc}\", MODEL_CLAUDE_NAME)\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(f\"Interpret Hypergraph: {hypergraph_desc}\", MODEL_CLAUDE_NAME)\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(f\"Interpret Correlation Heatmap: {correlation_heatmap_desc}\", MODEL_CLAUDE_NAME)\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(f\"Explain SHAP summary: {shap_analysis_info}\", MODEL_CLAUDE_NAME)\n",
        "            + \"\\n\\n\"\n",
        "        )\n",
        "\n",
        "        grok_enhanced_insights = (\n",
        "            analyze_text_with_llm(f\"Analyze correlation heatmap for root causes: {correlation_heatmap_desc}\", MODEL_GROK_ENHANCED_NAME)\n",
        "            + \"\\n\\n\"\n",
        "            + analyze_text_with_llm(f\"Interpret parallel coordinates plot in depth: {parallel_coords_desc}\", MODEL_GROK_ENHANCED_NAME)\n",
        "        )\n",
        "\n",
        "        combined_insights = f\"\"\"\n",
        "    Combined Insights Report: Anxiety Intervention Analysis\n",
        "\n",
        "    Grok-base Analysis:\n",
        "    {grok_insights}\n",
        "\n",
        "    Claude 3.7 Sonnet Analysis:\n",
        "    {claude_insights}\n",
        "\n",
        "    Grok-Enhanced Analysis:\n",
        "    {grok_enhanced_insights}\n",
        "\n",
        "    Synthesized Summary:\n",
        "    The analyses from our Mixture of Experts framework provides complementary insights into the anxiety intervention dataset. Grok-base highlights statistical robustness and potential causal relationships, noting the strong influence of pre-anxiety. Claude 3.7 Sonnet focuses on visual patterns and feature importance, observing variations between groups and the shift towards lower anxiety levels post-intervention. Grok-Enhanced adds nuanced interpretation of complex relationships, emphasizing the dominance of pre-anxiety with group-specific contextual nuances. The combined insights suggest a multifaceted impact influenced by the intervention, pre-intervention anxiety, and group dynamics, with significant variations and potential for deeper exploration of influential outliers and collaborative networks.\n",
        "\n",
        "    The correlation heatmap combined with regression-based causal inference offers a more robust approach to identifying root causes, revealing that [key finding from the analysis] is likely the primary factor influencing post-intervention anxiety levels. The parallel coordinates visualization further supports this by showing clear patterns in individual trajectories across groups.\n",
        "    \"\"\"\n",
        "        with open(os.path.join(output_path, \"insights.txt\"), \"w\") as f:\n",
        "            f.write(combined_insights)\n",
        "        return combined_insights\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating insights report: {e}\")\n",
        "        return \"Error: Could not generate insights report.\"\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to execute the analysis.\"\"\"\n",
        "    # 1. Data Loading and Validation\n",
        "    if not create_output_directory(OUTPUT_PATH):\n",
        "        return  # Exit if directory creation fails\n",
        "\n",
        "    synthetic_data = \"\"\"\n",
        "participant_id,group,anxiety_pre,anxiety_post,extra_feature1,extra_feature2\n",
        "1,Group 1,8,6,0.5,12\n",
        "    2,Group 2,6,4,0.3,15\n",
        "    3,Group 1,9,7,0.6,10\n",
        "    4,Group 2,7,5,0.4,18\n",
        "    5,Group 1,5,3,0.2,11\n",
        "    6,Group 2,8,6,0.5,14\n",
        "    7,Group 1,7,5,0.4,9\n",
        "    8,Group 2,6,4,0.3,20\n",
        "    9,Group 1,9,8,0.7,13\n",
        "    10,Group 2,5,3,0.2,16\n",
        "    \"\"\"\n",
        "    df = load_data_from_synthetic_string(synthetic_data)\n",
        "    required_columns = [\n",
        "        PARTICIPANT_ID_COLUMN,\n",
        "        GROUP_COLUMN,\n",
        "        ANXIETY_PRE_COLUMN,\n",
        "        ANXIETY_POST_COLUMN,\n",
        "        \"extra_feature1\",\n",
        "        \"extra_feature2\",\n",
        "    ]\n",
        "    if not validate_dataframe(df, required_columns):\n",
        "        return  # Exit if validation fails\n",
        "\n",
        "    # 2. Data Preprocessing\n",
        "    df = pd.get_dummies(df, columns=[GROUP_COLUMN], prefix=GROUP_COLUMN)  # One-hot encode\n",
        "    df = scale_data(df, [ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, \"extra_feature1\", \"extra_feature2\"])\n",
        "    if df is None:\n",
        "        return # Exit if scaling fails\n",
        "\n",
        "    # 3. Causal Structure Discovery\n",
        "    variables = [ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, \"extra_feature1\", \"extra_feature2\"] + [col for col in df.columns if col.startswith(f\"{GROUP_COLUMN}_\")]\n",
        "    causal_edges_info = discover_causal_structure_with_regression(df, variables, OUTPUT_PATH)\n",
        "    if causal_edges_info is None:\n",
        "        print(\"Causal structure discovery failed.  Continuing without causal graph.\")\n",
        "\n",
        "    # 4. SHAP Value Calculation\n",
        "    feature_columns = [ANXIETY_PRE_COLUMN, \"extra_feature1\", \"extra_feature2\", GROUP_COLUMN]\n",
        "    shap_analysis_info = calculate_shap_values(df, feature_columns, ANXIETY_POST_COLUMN, OUTPUT_PATH)\n",
        "\n",
        "    # 5. Data Visualization\n",
        "    colors = [\"#00FFFF\", \"#FF00FF\", \"#00FF00\"]  # Neon cyan, neon purple, neon green\n",
        "\n",
        "    kde_plot_desc = create_kde_plot(df, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, colors)\n",
        "    violin_plot_desc = create_violin_plot(df, GROUP_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, colors)\n",
        "    parallel_coords_desc = create_parallel_coordinates_plot(df, GROUP_COLUMN, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, colors)\n",
        "    hypergraph_desc = visualize_hypergraph(df, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, colors)\n",
        "    correlation_heatmap_desc = create_correlation_heatmap(df, OUTPUT_PATH, colors)\n",
        "\n",
        "    # 6. Statistical Summary\n",
        "    bootstrap_ci = perform_bootstrap(df[ANXIETY_POST_COLUMN], np.mean)\n",
        "    summary_stats_text = save_summary(df, bootstrap_ci, OUTPUT_PATH)\n",
        "\n",
        "    # 7. DDQN Agent (Simplified)\n",
        "    state_dim = len(variables) -1 # Exclude target\n",
        "    action_dim = 3  # Example: Increase, Decrease, Maintain intervention\n",
        "    agent = DDQNAgent(state_dim, action_dim)\n",
        "    # Placeholder training data (replace with actual data)\n",
        "    batch = [\n",
        "        (0, 0, 1, 1),  # Example: state 0, action 0, reward 1, next state 1\n",
        "        (1, 1, 2, 2),\n",
        "    ]\n",
        "    agent.learn(batch)\n",
        "    agent.update_target_network()\n",
        "    print(\"Simplified DDQN agent initialized and placeholder training completed.\")\n",
        "\n",
        "    # 8. LLM Insights Report\n",
        "    insights_report = generate_insights_report(\n",
        "        summary_stats_text,\n",
        "        causal_edges_info,\n",
        "        shap_analysis_info,\n",
        "        kde_plot_desc,\n",
        "        violin_plot_desc,\n",
        "        parallel_coords_desc,\n",
        "        hypergraph_desc,\n",
        "        correlation_heatmap_desc,\n",
        "        OUTPUT_PATH,\n",
        "    )\n",
        "    print(f\"Insights report generated:\\n{insights_report}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}